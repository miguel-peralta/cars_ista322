{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2slZhjZ+7QGoD2J8YspWi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miguel-peralta/cars_ista322/blob/main/cars.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cars Relational Databases\n",
        "ISTA 322 Final Project, Spring 2024 <br>\n",
        "Miguel Candido Aurora Peralta <br>\n",
        "## Extract\n",
        "### KBB Web Scraping\n",
        "The cars are separated into new and used cars categories. The lists new and used cars are on separate pages. These lists will be combined into one for this project.\n",
        "#### Used Cars\n",
        "\n"
      ],
      "metadata": {
        "id": "Zp2AZ6BeHomL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NQ4shfygHkQN"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we need to get a list of all of the URLs for the car models on KBB so that more information can be extracted from those pages."
      ],
      "metadata": {
        "id": "Q-_c9r4a-TWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_html_doc(url):\n",
        "  '''Returns the HTML document as a JSON response for the given URL'''\n",
        "  # requests HTML document for URL\n",
        "  response = requests.get(url)\n",
        "  # returns JSON response\n",
        "  return response.text"
      ],
      "metadata": {
        "id": "S1GQjmjbJ1MV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_kbb_df():\n",
        "  '''\n",
        "  Returns a dataframe containing the url, make, model, and year from the\n",
        "  relative URLs listed on the car models list pages.\n",
        "  Returns:\n",
        "    car_info (DataFrame): make, model, year, and url of each model\n",
        "  '''\n",
        "  # Create dataframe and lists to store info\n",
        "  car_info = pd.DataFrame()\n",
        "  urls = []\n",
        "  make = []\n",
        "  model = []\n",
        "  year = []\n",
        "  base_url = 'https://www.kbb.com'\n",
        "\n",
        "  for page in ['new', 'used']:\n",
        "    url = f'https://www.kbb.com/car-make-model-list/{page}'\n",
        "    # Create HTML object from url\n",
        "    html = get_html_doc(url)\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    # Create list to store relative URLS from the page\n",
        "    links = []\n",
        "    # Get all links from the page (the links to models all have the same style)\n",
        "    for link in soup.find_all('a', attrs={'style':\"padding:12px 8px;display:inline-block\"}):\n",
        "      # Add links to the list\n",
        "      links.append(link.get('href'))\n",
        "    # Split links using / as delimeter and add information to lists\n",
        "    for car in links:\n",
        "      urls.append(base_url+car)\n",
        "      link_split = car.split('/')\n",
        "      make.append(link_split[1])\n",
        "      model.append(link_split[2])\n",
        "      year.append(link_split[3])\n",
        "\n",
        "  # Use lists to populate dataframe\n",
        "  car_info['url'] = urls\n",
        "  car_info['make'] = make\n",
        "  car_info['model'] = model\n",
        "  car_info['year'] = year\n",
        "\n",
        "  return car_info\n"
      ],
      "metadata": {
        "id": "DvO3B-L45_FQ"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kbb = get_kbb_df()"
      ],
      "metadata": {
        "id": "RKJnlFAV7sGA"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_styles_urls(url):\n",
        "    '''\n",
        "    Given the URL to a year's model of a car, returns a list of the urls to the\n",
        "    styles of that model. If there is no style information available, returns a\n",
        "    1-element list with just the model page URL.\n",
        "    Args:\n",
        "      url (string): url to a year's model of a car\n",
        "    Returns:\n",
        "      styles (list): list of urls for that model's styles\n",
        "    '''\n",
        "    # Create HTML object from url\n",
        "    url = f'https://www.kbb.com/audi/a3/2022/'\n",
        "    html = get_html_doc(url)\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    styles = []\n",
        "    # The elements containing the style links are always 220px wide\n",
        "    for style in soup.find_all('a', attrs={'width': '220px'}):\n",
        "      # Add links to the list\n",
        "      styles.append(url+style.get('href'))\n",
        "    if len(styles) < 1:\n",
        "      styles.append(url)\n",
        "    return styles"
      ],
      "metadata": {
        "id": "lzvIXiUV-muw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in kbb.index:\n",
        "  kbb['styles'] = get_styles_urls(kbb['url'])"
      ],
      "metadata": {
        "id": "CQCVFjlcmFht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating make and model tables"
      ],
      "metadata": {
        "id": "_k10L_rVSLPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_make_table(kbb):\n",
        "  make = pd.DataFrame(columns = ['make'])\n",
        "  make_list = kbb['make'].unique()\n",
        "  make['make'] = make_list\n",
        "  make = make.reset_index(inplace=True)\n",
        "  make = make.rename(columns={'index':'make_id'})\n",
        "  return make"
      ],
      "metadata": {
        "id": "CDt5jqsISF13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make = create_make_table(kbb)"
      ],
      "metadata": {
        "id": "FVvosBA9TaRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_models_table(kbb, make):\n",
        "  models = pd.DataFrame(columns = ['make_id', 'year', 'styles'])\n",
        "  for i in kbb.index:\n",
        "    models = kbb"
      ],
      "metadata": {
        "id": "K93PFJInS7xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fEST_cBBSPRS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we need to retrieve the ends of the urls for the styles for each model of car. Some cars that are too new don't have any styles listed yet. In this case, we will just return an empty array as all of the information that would be contained on the individual style pages is already on the model page."
      ],
      "metadata": {
        "id": "_zcHhE9_-gS-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7JcSeZo_Lpih"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}